import cv2
import numpy as np
from ultralytics import YOLO
import time
from collections import defaultdict
import argparse
import torch
import os
import threading
class RGBBallTracker:
    def __init__(self, model_path, confidence_threshold=0.55, device='auto'):
        """
        åˆå§‹åŒ–RGBçƒè¿½è¸ªå™¨
        
        Args:
            model_path: YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            device: è®¾å¤‡é€‰æ‹© ('auto', 'cpu', 'cuda:0', 'cuda:1', etc.)
        """
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
        if device == 'auto':
            if torch.cuda.is_available():
                device = 'cuda:0'
                print(f"âœ“ è‡ªåŠ¨é€‰æ‹©GPU: {torch.cuda.get_device_name(0)}")
                print(f"âœ“ GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
            else:
                device = 'cpu'
                print("âš  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        else:
            if device.startswith('cuda') and not torch.cuda.is_available():
                print("âš  æŒ‡å®šGPUä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
                device = 'cpu'
            elif device.startswith('cuda'):
                gpu_id = int(device.split(':')[1]) if ':' in device else 0
                if gpu_id < torch.cuda.device_count():
                    print(f"âœ“ ä½¿ç”¨æŒ‡å®šGPU: {torch.cuda.get_device_name(gpu_id)}")
                else:
                    print(f"âš  GPU {gpu_id} ä¸å­˜åœ¨ï¼Œä½¿ç”¨GPU 0")
                    device = 'cuda:0'
        
        self.device = device
        self.confidence_threshold = confidence_threshold
        
        # åŠ è½½æ¨¡å‹
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        self.model = YOLO(model_path)
        
        # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        if device != 'cpu':
            print(f"ğŸ”„ å°†æ¨¡å‹ç§»åŠ¨åˆ° {device}...")
            self.model.to(device)
        
        print(f"âœ“ æ¨¡å‹å·²åŠ è½½åˆ° {device}")
        
        # GPUä¼˜åŒ–è®¾ç½®
        if device.startswith('cuda'):
            self._setup_gpu_optimization()
        
        # å®šä¹‰é¢œè‰²æ˜ å°„ (BGRæ ¼å¼)
        self.colors = {
            'red': (0, 0, 255),
            'green': (0, 255, 0),
            'blue': (255, 0, 0)
        }
        
        # ç±»åˆ«åç§°æ˜ å°„ï¼ˆæ ¹æ®ä½ çš„æ¨¡å‹è®­ç»ƒæ—¶çš„ç±»åˆ«é¡ºåºè°ƒæ•´ï¼‰
        self.class_names = {
            0: 'red_ball',
            1: 'green_ball', 
            2: 'blue_ball'
        }
        
        # è¿½è¸ªå†å²è®°å½•
        self.tracking_history = defaultdict(list)
        self.frame_count = 0
        
        # æ€§èƒ½ç›‘æ§
        self.inference_times = []
        self.total_inference_time = 0
        
        # GPUé¢„çƒ­
        if device.startswith('cuda'):
            self._warmup_model()
    
    def _setup_gpu_optimization(self):
        """è®¾ç½®GPUä¼˜åŒ–"""
        try:
            # å¯ç”¨CUDNNåŸºå‡†æ¨¡å¼ï¼ˆå›ºå®šè¾“å…¥å°ºå¯¸æ—¶æœ‰æ•ˆï¼‰
            torch.backends.cudnn.benchmark = True
            print("âœ“ CUDNNåŸºå‡†æ¨¡å¼å·²å¯ç”¨")
        except Exception as e:
            print(f"âš  GPUä¼˜åŒ–è®¾ç½®å¤±è´¥: {e}")
    
    def _warmup_model(self, warmup_frames=5):
        """GPUæ¨¡å‹é¢„çƒ­"""
        print("ğŸ”¥ GPUæ¨¡å‹é¢„çƒ­ä¸­...")
        dummy_frame = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
        
        for i in range(warmup_frames):
            with torch.no_grad():
                _ = self.model(dummy_frame, verbose=False)
            if torch.cuda.is_available():
                torch.cuda.synchronize()
        
        print("âœ“ GPUé¢„çƒ­å®Œæˆ")
        
    def process_frame(self, frame, isPrintInfo=True):
        """
        å¤„ç†å•å¸§å›¾åƒ
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            isPrintInfo: æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            processed_frame: å¤„ç†åçš„å›¾åƒå¸§
            detections: æ£€æµ‹ç»“æœ
        """


        # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
        inference_start = time.perf_counter()
        
        # è¿è¡ŒYOLOæ¨ç† - GPUä¼˜åŒ–æ¨ç†
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—èŠ‚çœæ˜¾å­˜
            if self.device.startswith('cuda'):
                # GPUæ¨ç†æ—¶ä½¿ç”¨æ··åˆç²¾åº¦åŠ é€Ÿ
                with torch.cuda.amp.autocast():
                    results = self.model(frame, conf=self.confidence_threshold, verbose=False)
                # ç¡®ä¿GPUæ“ä½œå®Œæˆ
                torch.cuda.synchronize()
            else:
                # CPUæ¨ç†
                results = self.model(frame, conf=self.confidence_threshold, verbose=False)
        
        # è®°å½•æ¨ç†æ—¶é—´
        inference_end = time.perf_counter()
        inference_time = inference_end - inference_start
        self.inference_times.append(inference_time)
        self.total_inference_time += inference_time
        
        # å¤åˆ¶å¸§ç”¨äºç»˜åˆ¶
        processed_frame = frame.copy()
        detections = []
        
        # å¤„ç†æ£€æµ‹ç»“æœ
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])
                    # è·å–ç±»åˆ«åç§°
                    class_name = self.class_names.get(class_id, f'class_{class_id}')
                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2
                    # è®°å½•æ£€æµ‹ç»“æœ
                    detection = {
                        'bbox': (x1, y1, x2, y2),
                        'center': (center_x, center_y),
                        'confidence': confidence,
                        'class_name': class_name,
                        'class_id': class_id
                    }
                    detections.append(detection)

        # åªä¿ç•™æ¯ç§çƒç±»å‹ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ª
        best_detections = {}
        for det in detections:
            cname = det['class_name']
            if cname not in best_detections or det['confidence'] > best_detections[cname]['confidence']:
                best_detections[cname] = det
        detections = list(best_detections.values())

        # ç»˜åˆ¶å’Œè¿½è¸ªä»…å¯¹ç­›é€‰åçš„æ£€æµ‹è¿›è¡Œ
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            center_x, center_y = detection['center']
            confidence = detection['confidence']
            class_name = detection['class_name']
            color = self.get_color_for_class(class_name)
            # æ›´æ–°è¿½è¸ªå†å²
            self.tracking_history[class_name].append((center_x, center_y))
            if len(self.tracking_history[class_name]) > 50:
                self.tracking_history[class_name].pop(0)
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(processed_frame, (x1, y1), (x2, y2), color, 2)
            # ç»˜åˆ¶æ ‡ç­¾
            label = f'{class_name}: {confidence:.2f}'
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(processed_frame, 
                        (x1, y1 - label_size[1] - 10), 
                        (x1 + label_size[0], y1), 
                        color, -1)
            cv2.putText(processed_frame, label, 
                      (x1, y1 - 5), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(processed_frame, (center_x, center_y), 5, color, -1)

        # ç»˜åˆ¶è¿½è¸ªè½¨è¿¹
        self.draw_tracking_trails(processed_frame)

        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
        if isPrintInfo:
            self.draw_statistics(processed_frame, detections, inference_time)

        return processed_frame, detections
    
    def get_color_for_class(self, class_name):
        """æ ¹æ®ç±»åˆ«åç§°è·å–é¢œè‰²"""
        if 'red' in class_name.lower():
            return self.colors['red']
        elif 'green' in class_name.lower():
            return self.colors['green']
        elif 'blue' in class_name.lower():
            return self.colors['blue']
        else:
            return (128, 128, 128)  # ç°è‰²ä½œä¸ºé»˜è®¤é¢œè‰²
    
    def draw_tracking_trails(self, frame):
        """ç»˜åˆ¶è¿½è¸ªè½¨è¿¹"""
        for class_name, points in self.tracking_history.items():
            if len(points) > 1:
                color = self.get_color_for_class(class_name)
                # ç»˜åˆ¶è½¨è¿¹çº¿
                for i in range(1, len(points)):
                    cv2.line(frame, points[i-1], points[i], color, 1)
    
    def draw_statistics(self, frame, detections, inference_time):
        """ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯"""
        h, w = frame.shape[:2]
        
        # ç»Ÿè®¡å„ç±»çƒçš„æ•°é‡
        stats = defaultdict(int)
        for det in detections:
            stats[det['class_name']] += 1
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        avg_inference_time = np.mean(self.inference_times[-30:]) if self.inference_times else 0
        theoretical_fps = 1 / avg_inference_time if avg_inference_time > 0 else 0
        
        # ç»˜åˆ¶èƒŒæ™¯ - æ‰©å¤§ä»¥æ˜¾ç¤ºæ›´å¤šä¿¡æ¯
        info_height = 180 if self.device.startswith('cuda') else 140
        cv2.rectangle(frame, (10, 10), (350, info_height), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (350, info_height), (255, 255, 255), 2)
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        y_pos = 30
        cv2.putText(frame, f'Frame: {self.frame_count}', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        y_pos += 20
        cv2.putText(frame, f'Device: {self.device}', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
        y_pos += 20
        cv2.putText(frame, f'Inference: {inference_time*1000:.1f}ms', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        y_pos += 20
        cv2.putText(frame, f'Avg FPS: {theoretical_fps:.1f}', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        # æ˜¾ç¤ºGPUä¿¡æ¯
        if self.device.startswith('cuda') and torch.cuda.is_available():
            y_pos += 20
            memory_used = torch.cuda.memory_allocated() / 1024**3
            cv2.putText(frame, f'GPU Mem: {memory_used:.2f}GB', 
                       (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
        
        # æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡
        y_pos += 25
        for class_name in ['red_ball', 'green_ball', 'blue_ball']:
            count = stats.get(class_name, 0)
            color = self.get_color_for_class(class_name)
            cv2.putText(frame, f'{class_name}: {count}', 
                       (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            y_pos += 20
        
        self.frame_count += 1
    
    def get_performance_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if not self.inference_times:
            return None
        
        return {
            'avg_inference_ms': np.mean(self.inference_times) * 1000,
            'min_inference_ms': np.min(self.inference_times) * 1000,
            'max_inference_ms': np.max(self.inference_times) * 1000,
            'theoretical_fps': 1 / np.mean(self.inference_times),
            'total_frames': len(self.inference_times)
        }

def test_on_webcam(model_path, isPrintInfo=True, device='auto', isSaveTraceEnable=False):
    """ä½¿ç”¨æ‘„åƒå¤´æµ‹è¯•æ¨¡å‹"""
    tracker = RGBBallTracker(model_path, device=device)
    cap = cv2.VideoCapture(1)
    
    # æ‘„åƒå¤´ä¼˜åŒ–è®¾ç½®
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # å‡å°‘ç¼“å†²å»¶è¿Ÿ
    
    if not cap.isOpened():
        print("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
    
    print("å¼€å§‹æ‘„åƒå¤´æµ‹è¯•ï¼ŒæŒ‰ 'q' é€€å‡º")
    fps_counter = 0
    start_time = time.time()

    if isSaveTraceEnable:
        # è½¨è¿¹è®°å½•ç›¸å…³
        tracking = False
        ball_tracks = {'red_ball': [], 'green_ball': [], 'blue_ball': []}
        print("æŒ‰ s å¼€å§‹/æš‚åœè¿½è¸ªï¼ŒæŒ‰ q é€€å‡ºå¹¶ä¿å­˜è½¨è¿¹")
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # å¤„ç†å¸§
            processed_frame, detections = tracker.process_frame(frame, isPrintInfo)
            
            # è®¡ç®—å®é™…FPS
            fps_counter += 1
            if fps_counter % 30 == 0:
                elapsed = time.time() - start_time
                actual_fps = fps_counter / elapsed
                print(f"å®é™…FPS: {actual_fps:.2f}, æ£€æµ‹åˆ°çƒæ•°é‡: {len(detections)}")
                
                # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
                stats = tracker.get_performance_stats()
                if stats:
                    print(f"æ¨ç†æ—¶é—´: {stats['avg_inference_ms']:.1f}ms, "
                          f"ç†è®ºFPS: {stats['theoretical_fps']:.1f}")
            
            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('RGB Ball Tracking - GPU Accelerated', processed_frame)
            key = cv2.waitKey(1) & 0xFF
            if isSaveTraceEnable:
                if tracking:
                    update_ball_tracks(ball_tracks, detections)

            # æŒ‰ 'q' é€€å‡º
            
            if key == ord('q'):
                
                break
            elif key == ord('s'):
                if isSaveTraceEnable:
                    tracking = not tracking
                    print("è¿½è¸ª" + ("å¼€å§‹" if tracking else "æš‚åœ"))
                else:
                    pass
        if isSaveTraceEnable:
            save_ball_tracks(ball_tracks)
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        
        # æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
        stats = tracker.get_performance_stats()
        if stats:
            print(f"\n=== æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š ===")
            print(f"è®¾å¤‡: {tracker.device}")
            print(f"æ€»å¸§æ•°: {stats['total_frames']}")
            print(f"å¹³å‡æ¨ç†æ—¶é—´: {stats['avg_inference_ms']:.2f}ms")
            print(f"ç†è®ºæœ€å¤§FPS: {stats['theoretical_fps']:.1f}")
            print(f"æ¨ç†æ—¶é—´èŒƒå›´: {stats['min_inference_ms']:.1f}-{stats['max_inference_ms']:.1f}ms")

def test_on_video(model_path, video_path, output_path=None, device='auto'):
    """åœ¨è§†é¢‘æ–‡ä»¶ä¸Šæµ‹è¯•æ¨¡å‹"""
    tracker = RGBBallTracker(model_path, device=device)
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return
    
    # è·å–è§†é¢‘å±æ€§
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}fps, {total_frames}å¸§")
    print(f"ä½¿ç”¨è®¾å¤‡: {tracker.device}")
    
    # è®¾ç½®è¾“å‡ºè§†é¢‘
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_idx = 0
    start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # å¤„ç†å¸§
            processed_frame, detections = tracker.process_frame(frame, True)
            
            # ä¿å­˜åˆ°è¾“å‡ºè§†é¢‘
            if output_path:
                out.write(processed_frame)
            
            # æ˜¾ç¤ºè¿›åº¦
            frame_idx += 1
            if frame_idx % 30 == 0:
                progress = (frame_idx / total_frames) * 100
                elapsed = time.time() - start_time
                processing_fps = frame_idx / elapsed
                print(f"å¤„ç†è¿›åº¦: {progress:.1f}% ({frame_idx}/{total_frames}), "
                      f"å¤„ç†é€Ÿåº¦: {processing_fps:.1f}fps")
            
            # æ˜¾ç¤ºç»“æœï¼ˆå¯é€‰ï¼‰
            cv2.imshow('RGB Ball Tracking', processed_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­å¤„ç†")
    
    finally:
        cap.release()
        if output_path:
            out.release()
            print(f"è¾“å‡ºè§†é¢‘å·²ä¿å­˜åˆ°: {output_path}")
        
        cv2.destroyAllWindows()
        
        # æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
        elapsed_total = time.time() - start_time
        avg_processing_fps = frame_idx / elapsed_total if elapsed_total > 0 else 0
        
        stats = tracker.get_performance_stats()
        if stats:
            print(f"\n=== è§†é¢‘å¤„ç†æ€§èƒ½æŠ¥å‘Š ===")
            print(f"è®¾å¤‡: {tracker.device}")
            print(f"å¤„ç†å¸§æ•°: {frame_idx}/{total_frames}")
            print(f"æ€»å¤„ç†æ—¶é—´: {elapsed_total:.1f}s")
            print(f"å¹³å‡å¤„ç†é€Ÿåº¦: {avg_processing_fps:.1f}fps")
            print(f"å¹³å‡æ¨ç†æ—¶é—´: {stats['avg_inference_ms']:.2f}ms")

def main():
    parser = argparse.ArgumentParser(description='RGBçƒè¿½è¸ªYOLOæ¨¡å‹æµ‹è¯• - GPUåŠ é€Ÿç‰ˆ')
    parser.add_argument('--model', required=True, help='YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--source', default='webcam', 
                       help='è¾“å…¥æº: webcam æˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', help='è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆä»…å¯¹è§†é¢‘æ–‡ä»¶æœ‰æ•ˆï¼‰')
    parser.add_argument('--conf', type=float, default=0.55, 
                       help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--device', default='auto',
                       help='æ¨ç†è®¾å¤‡: auto, cpu, cuda:0, cuda:1 ç­‰')
    parser.add_argument('--info', action='store_true',
                       help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ RGBçƒè¿½è¸ªæ¨¡å‹æµ‹è¯• - GPUåŠ é€Ÿç‰ˆ")
    print(f"ğŸ“¦ æ¨¡å‹æ–‡ä»¶: {args.model}")
    print(f"ğŸ–¥ï¸ æ¨ç†è®¾å¤‡: {args.device}")
    print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {args.conf}")
    print(f"ğŸ“Š æ˜¾ç¤ºä¿¡æ¯: {args.info}")
    
    if args.source == 'webcam':
        test_on_webcam(args.model, args.info, args.device)
    else:
        test_on_video(args.model, args.source, args.output, args.device)


def save_ball_tracks(tracks_dict, out_dir=".\\traces",suffix:int = 1):
    """
    ä¿å­˜çƒè½¨è¿¹åˆ°txtæ–‡ä»¶ï¼Œtracks_dict: {class_name: [(x, y), ...]}
    """
    for cname, points in tracks_dict.items():
        fname = os.path.join(out_dir, f"{cname}_{suffix}.txt")
        with open(fname, "w") as f:
            for x, y in points:
                f.write(f"{x},{y}\n")

def update_ball_tracks(tracks_dict, detections):
    """
    æ ¹æ®å½“å‰å¸§æ£€æµ‹ç»“æœï¼Œæ›´æ–°è½¨è¿¹å­—å…¸
    """
    for det in detections:
        cname = det['class_name']
        center = det['center']
        tracks_dict[cname].append(center)




if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œï¼Œä½¿ç”¨é»˜è®¤å‚æ•°è¿›è¡Œæµ‹è¯•
    model_path = "./yolo/ball.pt"
    
    print("ğŸš€ RGBçƒè¿½è¸ªæ¨¡å‹æµ‹è¯• - GPUåŠ é€Ÿç‰ˆ")
    print("=" * 50)
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    if torch.cuda.is_available():
        print(f"âœ“ æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
        print(f"âœ“ GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"âœ“ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    else:
        print("âš  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPU")
    
    print("=" * 50)
    print("1. æ‘„åƒå¤´æµ‹è¯•")
    print("2. è§†é¢‘æ–‡ä»¶æµ‹è¯•")
    
    choice = input("è¯·é€‰æ‹©æµ‹è¯•æ–¹å¼ (1/2): ")

    isPrintInfo = input('æ˜¯å¦ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯ï¼Ÿ(y/n): ')
    if isPrintInfo.lower() == 'y':
        print("âœ“ å°†ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯")
        isPrintInfo = True
    else:
        print("âœ— ä¸ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯")
        isPrintInfo = False
    
    device = input('é€‰æ‹©è®¾å¤‡ (auto/cpu/cuda:0): ').strip()
    if not device:
        device = 'auto'
    
    print(f"ğŸ“± é€‰æ‹©è®¾å¤‡: {device}")
    
    if choice == "1":
        test_on_webcam(model_path, isPrintInfo, device, True)
    elif choice == "2":
        video_path = input("è¯·è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„: ")
        output_path = input("è¯·è¾“å…¥è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆå›è½¦è·³è¿‡ï¼‰: ")
        if not output_path:
            output_path = None
        test_on_video(model_path, video_path, output_path, device)
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")